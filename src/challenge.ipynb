{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03308d88",
   "metadata": {},
   "source": [
    "## LT Challenge Solution ## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc78f22",
   "metadata": {},
   "source": [
    "### Objetivos\n",
    "1. The main solution goal of this case is to explore memory usage and optimization within a distributed and scalable data processing environment like Spark.\n",
    "2. Explore scalable cloud solutions such as Cloud Storage, Cloud Build, and Cloud Run on GCP.\n",
    "3. Deploy a reproducible environment using Docker ready to run Jupyter and PySpark\n",
    "4. Deploy an automated Cloud Build CI for my Docker image to GCP Artifact Registry.\n",
    "5. Establish and adhere to a Git flow to establish an efficient workflow for organizing features, builds, and testing tasks.\n",
    "6. Implement test-driven development (TDD) to address challenging questions.\n",
    "7. Implement data transformations to define data quality layers.\n",
    "8. Explore data transformation analytical techniques to address challenging questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6698e7d",
   "metadata": {},
   "source": [
    "## LT Data Analysis Challenge - step 1 --> q1_memory.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceae10c",
   "metadata": {},
   "source": [
    "### Description\n",
    "The script performs the following operations:\n",
    "\n",
    "1. Spark initialization: Create a Spark session to process the data.\n",
    "2. Reading JSON File: Reads data from a specified JSON file, using a defined schema that includes fields such as identifier, username, message, and date.\n",
    "3. Data analysis:\n",
    "     - Group data by date and count messages to identify the 10 dates with the most activity.\n",
    "     - Filter the data to only keep messages from these dates.\n",
    "     - Count each user's messages on these dates to determine the most active user per day.\n",
    "4. Results: The script returns a list of tuples, each containing a date and the name of the most active user on that date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a04c77",
   "metadata": {},
   "source": [
    "### Execution Steps\n",
    "To execute this Spark application, follow these steps:\n",
    "1. Install the necessary Python packages (`requirements.txt`)\n",
    "2. The data file ´´farmers-protest-tweets-2021-2-4.json´´ is in the data/raw folder, compressed in a .rar, it must be decompressed before executing the code.\n",
    "3. Run the Spark application, passing the path to the JSON file as an argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d017187",
   "metadata": {},
   "source": [
    "### Review the results:\n",
    "The script will print the results to the console, showing the dates with the most messages and the most active user on those dates.\n",
    "The memory usage analysis results will be displayed in the console if memory_profiler is active."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fe1903",
   "metadata": {},
   "source": [
    "## LT Data Analysis Challenge - step 2 --> q1_time.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a551ca30",
   "metadata": {},
   "source": [
    "### Description\n",
    "The script performs the following operations:\n",
    "\n",
    "1. Initializes a Spark session and reads data from the specified file.\n",
    "2. Persist the DataFrame in memory and disk to optimize performance.\n",
    "3. Group the data by creation date and count the posts for each date.\n",
    "4. Filter the 10 dates with the most posts and get the most active users on those dates.\n",
    "5. We use a window function to sort users by their activity and select the most active for each date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8f4051",
   "metadata": {},
   "source": [
    "### Execution Steps\n",
    "To execute this Spark application, follow these steps:\n",
    "1. Install the necessary Python packages (`requirements.txt`)\n",
    "2. The data file ´´farmers-protest-tweets-2021-2-4.json´´ is in the data/raw folder, compressed in a .rar, it must be decompressed before executing the code.\n",
    "3. Run the script from the command line, passing the JSON file path as an argument:\n",
    "Copy code\n",
    "```bash \n",
    "python q1_memory.py /data/raw/farmers-protest-tweets-2021-2-4.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78306d2",
   "metadata": {},
   "source": [
    "### Review the results:\n",
    "The script will print the results to the console, showing the 10 dates with the most posts and gets the most active users on those dates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f14257",
   "metadata": {},
   "source": [
    "## LT Data Analysis Challenge - step 3 --> q1_memory.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aee79f",
   "metadata": {},
   "source": [
    "### Description\n",
    "The script performs the following operations:\n",
    "\n",
    "1. Initialize a Spark session and read tweet data from the JSON file.\n",
    "2. Extract emojis from the tweet content using a user-defined function (UDF).\n",
    "3. Count the occurrences of each emoji.\n",
    "4. Sort the emojis by frequency, with alphabetical order for tiebreakers.\n",
    "5. Returns the 10 most used emojis along with their counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa74d6d9",
   "metadata": {},
   "source": [
    "### Execution Steps\n",
    "To execute this Spark application, follow these steps:\n",
    "1. Install the necessary Python packages (`requirements.txt`)\n",
    "2. The data file ´´farmers-protest-tweets-2021-2-4.json´´ is in the data/raw folder, compressed in a .rar, it must be decompressed before executing the code.\n",
    "3. Run the script from the command line, passing the JSON file path as an argument:\n",
    "Copy code\n",
    "```bash \n",
    "python q2_memory.py /data/raw/farmers-protest-tweets-2021-2-4.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3b680c",
   "metadata": {},
   "source": [
    "### Review the results:\n",
    "The script will print the results to the console, displaying 10 most used emojis along with their counts.\n",
    "The memory usage analysis results will be displayed in the console if memory_profiler is active."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
