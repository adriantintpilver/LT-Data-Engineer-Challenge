{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03308d88",
   "metadata": {},
   "source": [
    "file_path = \"../data/raw/farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6698e7d",
   "metadata": {},
   "source": [
    "## LT Data Analysis Challenge - step 1 --> q1_memory.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceae10c",
   "metadata": {},
   "source": [
    "### Description\n",
    "This notebook explain a Spark application for LT challenge, that analyzes a JSON file to find the days with the most messages and the most active user on those days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941601a9",
   "metadata": {},
   "source": [
    "### How the Script Works\n",
    "1. **Initialize Spark**: Starts a Spark session to process the data.\n",
    "2. **Read the JSON file**: Reads data from a specified JSON file, using a predefined schema.\n",
    "3. **Data Analysis**:\n",
    "   - Groups the data by date and counts the messages to identify the top 10 active days.\n",
    "   - Filters the data to keep only the messages from these top days.\n",
    "   - Counts the messages per user on these days to determine the most active user per day.\n",
    "4. **Results**: Returns a list of tuples, each containing a date and the name of the most active user on that date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a04c77",
   "metadata": {},
   "source": [
    "### Execution Steps\n",
    "To execute this Spark application, follow these steps:\n",
    "1. Install the necessary Python packages (`pyspark` and `memory_profiler`).\n",
    "2. The data file ´´farmers-protest-tweets-2021-2-4.json´´ is in the data/raw folder, compressed in a .rar, it must be decompressed before executing the code.\n",
    "3. Run the Spark application, passing the path to the JSON file as an argument."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
